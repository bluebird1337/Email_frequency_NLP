{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16c9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b867986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    tokens = text.split()   \n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "def tokenize2(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    tokens = text.split()   \n",
    "    return tokens\n",
    "\n",
    "def calculate_frequency(tokens):    \n",
    "    word_count_dict = Counter() \n",
    "    for w in tokens:\n",
    "        word_count_dict[w] += 1       \n",
    "    return word_count_dict\n",
    "\n",
    "def get_ngram(tokens, n=2):\n",
    "    tokens = ngrams(tokens, n)   \n",
    "    return [ ' '.join(grams) for grams in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b850fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "path = 'C:/Users/user/Desktop/Email_frequency_NLP_0316/chapter_txtfile/1Acceptances.txt';\n",
    "file_path = os.path.join('data', path)\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50cc474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1acceptancesthe', 'mind', 'gives', 'us', 'thousands', 'ways', 'say', 'sonly', 'one', 'way']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(text[0])\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad6c667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 unigrams:\n",
      "[(('invitation',), 21), (('say',), 13), (('accept',), 13), (('reply',), 12), (('pleasure',), 10)]\n"
     ]
    }
   ],
   "source": [
    "news_unigrams = ngrams(tokens, 1)\n",
    "news_unigrams_freq = Counter(news_unigrams)\n",
    "print(\"Top 5 unigrams:\\n{}\".format(news_unigrams_freq.most_common(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c44c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize2(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c66ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 trigrams:\n",
      "[(('of', 'the'), 14), (('to', 'say'), 12), (('the', 'invitation'), 9), (('to', 'accept'), 7), (('how', 'to'), 7)]\n"
     ]
    }
   ],
   "source": [
    "# obtain all trigrams\n",
    "news_bigrams = ngrams(tokens, 2)\n",
    "# count occurrences of each trigram\n",
    "news_bigrams_freq = Counter(news_bigrams)\n",
    "# review top 5 frequent trigrams in the news\n",
    "print(\"Top 5 trigrams:\\n{}\".format(news_bigrams_freq.most_common(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c4defa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 trigrams:\n",
      "[(('to', 'say', 'it'), 7), (('how', 'to', 'say'), 6), (('we', 'are', 'pleased'), 5), (('are', 'pleased', 'to'), 5), (('the', 'details', 'of'), 3)]\n"
     ]
    }
   ],
   "source": [
    "news_trigrams = ngrams(tokens, 3)\n",
    "\n",
    "news_trigrams_freq = Counter(news_trigrams)\n",
    "print(\"Top 5 trigrams:\\n{}\".format(news_trigrams_freq.most_common(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65171cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of the', 'to say', 'the invitation', 'to accept', 'how to']\n",
      "['to say it', 'how to say', 'we are pleased', 'are pleased to', 'the details of']\n"
     ]
    }
   ],
   "source": [
    "bigram=[]\n",
    "for i in list(news_bigrams_freq.most_common(5)):\n",
    "    tmp = ' '.join(i[0])\n",
    "    bigram.append(tmp)\n",
    "print(bigram)\n",
    "\n",
    "trigram=[]\n",
    "for i in list(news_trigrams_freq.most_common(5)):\n",
    "    tmp = ' '.join(i[0])\n",
    "    trigram.append(tmp)\n",
    "print(trigram)\n",
    "# news_bigrams_freq\n",
    "# news_trigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9cfd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(n):\n",
    "    # read file\n",
    "    path = 'C:/Users/user/Desktop/Email_frequency_NLP_0316/chapter_txtfile/'+ n + '.txt';\n",
    "    file_path = os.path.join('data', path)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "    tokens = tokenize(text[0])\n",
    "    tokens2 = tokenize2(text[0])\n",
    "    \n",
    "    bigram=[]\n",
    "    news_bigrams = ngrams(tokens, 2)\n",
    "    news_bigrams_freq = Counter(news_bigrams)\n",
    "    for i in list(news_bigrams_freq.most_common(5)):\n",
    "        tmp = ' '.join(i[0])\n",
    "        bigram.append(tmp)\n",
    "    print(bigram)\n",
    "\n",
    "    trigram=[]\n",
    "    news_trigrams = ngrams(tokens2, 3)\n",
    "    news_trigrams_freq = Counter(news_trigrams)\n",
    "    for i in list(news_trigrams_freq.most_common(5)):\n",
    "        tmp = ' '.join(i[0])\n",
    "        trigram.append(tmp)\n",
    "    print(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ec7f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "CH1 = '1Acceptances'\n",
    "CH2 = '2Acknowledgments andConfirmations'\n",
    "CH3 = '3Letters of Adjustment'\n",
    "CH4 = '4Advice'\n",
    "CH5 = '5Anniversaries and Birthdays'\n",
    "CH6 = '6Announcements'\n",
    "CH7 = '7Apologies'\n",
    "CH8 = '8Letters of Application'\n",
    "CH9 = '9Appointments and Interviews'\n",
    "CH10 = '10Letters of Appreciation'\n",
    "# CH11 = \n",
    "# CH12 =\n",
    "# CH13 =\n",
    "# CH14 =\n",
    "# CH15 =\n",
    "# CH16 =\n",
    "# CH17 =\n",
    "# CH18 =\n",
    "# CH19 =\n",
    "# CH20 =\n",
    "# CH21 =\n",
    "# CH22 =\n",
    "# CH23 =\n",
    "# CH24 =\n",
    "# CH25 =\n",
    "# CH26 =\n",
    "# CH27 =\n",
    "# CH28 =\n",
    "# CH29 =\n",
    "# CH30 =\n",
    "# CH31 =\n",
    "# CH32 =\n",
    "# CH33 =\n",
    "# CH34 =\n",
    "# CH35 =\n",
    "# CH36 =\n",
    "# CH37 =\n",
    "# CH38 =\n",
    "# CH39 =\n",
    "# CH40 =\n",
    "# CH41 =\n",
    "# CH42 =\n",
    "# CH43 =\n",
    "# CH44 =\n",
    "# CH45 =\n",
    "# CH46 =\n",
    "# CH47 =\n",
    "# CH48 =\n",
    "# CH49 =\n",
    "# CH50 =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df78d85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['would like', 'next week', 'plastic tubing', 'e mail', 'either us']\n",
      "['to meet with', 'would like to', 'to say it', 'meet with you', 'i would like']\n"
     ]
    }
   ],
   "source": [
    "function(CH9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
